{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation of Gradient Descent.\n",
    "        For example of the derivation i am going to use Mean Square Error (MSE).\n",
    "$$\n",
    "y \\  is \\ actual \\\\  \n",
    "y^{pred} \\ is \\ model \\ going \\ to find \\\\ \n",
    "y^{pred} = wx + b \\\\\n",
    "MSE = \\frac{1}{n}\\sum_{i = 0}^{n} (y_i - y^{pred}_i)^{2}\n",
    "$$\n",
    "\n",
    "To reduce the cost function need to get the optmized value for w and b, To get the optmize value of y based on the x need to find the optmize the w and b.\n",
    "\n",
    "$MSE = \\frac{1}{n}\\sum_{i = 0}^{n} (y_i - (wx_i + b))^{2}$\n",
    "\n",
    "To calculate the gradient of w and b, need to calculate the chain rule.\n",
    "\n",
    "# Why chain rule? \n",
    " w and b is in inner function.\n",
    "\n",
    "## Explain chain rule. \n",
    "\n",
    "To calculate the derivate of x. 1st calculate the derivate of outer function, Then calculate the derivative of inner function and multiply them.\n",
    "\n",
    "calculate the derivative of x.\n",
    "\n",
    "\n",
    "$\\displaystyle \\frac{\\partial }{\\partial x} (f[g(x)])$\n",
    "\n",
    "\n",
    "$\\displaystyle \\frac{\\partial }{\\partial x} (f[g(x)]) =  f^{'}[g(x)].g^{'}(x)$  \n",
    "\n",
    "example 1. \n",
    "$$\\displaystyle \\frac{\\partial }{\\partial x} [5x + 3]^4 =  4[5x+3] ^ {3} . [5 + 0] \\\\ \n",
    "= 4[5x+3] ^ {3} . 5  \\\\\n",
    "= 20 [5x + 3]^{3}\n",
    "$$\n",
    "\n",
    "example 2. \n",
    "$$\\displaystyle \\frac{\\partial }{\\partial x} {[x^{2} - 3x]}^{5} =  5[x^{2} - 3x]^{4} . [2x - 3] $$\n",
    "\n",
    "Back to MSE\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n}\\sum_{i = 0}^{n} (y - (wx + b))^{2} \\\\\n",
    "derivation \\ of \\ MSE=  \\frac{1}{n}\\sum_{i = 0}^{n} 2(y - (wx + b)) . (Partial \\ derivation \\ of \\ w \\ and \\ b) -> eq 1 \\\\\n",
    "$$\n",
    "(Partial derivation of w and b) this part is going to replace by derivation of w and b   \n",
    "Calculate the inner derivation of w and b  \n",
    "To find two different derivation need to calculate partial derivation  \n",
    "\n",
    "Partial derivation of w\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial }{\\partial w} (y - (wx + b)) =  -x $$\n",
    "\n",
    "Combine with eq1\n",
    "$$\n",
    "\n",
    "=  \\frac{1}{n}\\sum_{i = 0}^{n} 2(y - (wx + b))\\ . -x \\\\\n",
    "=  \\frac{1}{n}\\sum_{i = 0}^{n} -2x(y - (wx + b))\\  \\\\\n",
    "$$\n",
    "Above is final derivation of w \n",
    "\\\n",
    "\\\n",
    "Partial derivation of b\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial }{\\partial b} (y - (wx + b)) =  -1 $$\n",
    "Combine with eq1\n",
    "$$\n",
    "\n",
    "=  \\frac{1}{n}\\sum_{i = 0}^{n} 2(y - (wx + b))\\ . -1 \\\\\n",
    "=  \\frac{1}{n}\\sum_{i = 0}^{n} -2(y - (wx + b))\\ \\\\\n",
    "$$\n",
    "Above is final derivation of w   \n",
    "In the final derivation 2 is small value so it can be negligible.\n",
    "\n",
    "$$\n",
    "\\displaystyle \\frac{\\partial }{\\partial w} =  - \\frac{1}{n}\\sum_{i = 0}^{n} x(y - (wx + b)) \\\\\n",
    " \\\\\n",
    "\\displaystyle \\frac{\\partial }{\\partial b} =   - \\frac{1}{n}\\sum_{i = 0}^{n} (y - (wx + b))\n",
    "$$\n",
    "\n",
    "\\- is moved to starting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next [Gradient](./gradient/Gradient.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
